---
name: bug-audit
description: Comprehensive bug audit for Node.js web projects. Activate when user asks to audit, review, check bugs, find vulnerabilities, or do security/quality review on a project. Works by dissecting the project's actual code to build project-specific check matrices, then exhaustively verifying each item â€” not by running a generic checklist. Supports games, data tools, WeChat apps, API services, bots, and dashboards.
---

# Bug Audit â€” Dissect, Then Verify

Do NOT run a generic checklist. Instead: read the code, extract every auditable entity, then exhaustively question each one.

## Phase 1: Dissect (10-15 min)

Read all project files. Build 7 tables. These tables ARE the audit â€” everything found here gets verified in Phase 2.

### Table 1: API Endpoints

For every route in server-side code:

```
| # | Method | Path | Auth? | Params validated? | Precondition | Returns | Attack vector |
```

For each endpoint, ask:
- Can I call this without authentication?
- Can I pass 0, negative, NaN, huge numbers, arrays, objects?
- Can I skip a prerequisite API and call this directly?
- What happens if I call this 100 times per second?
- Does the response leak sensitive data (openid, internal IDs, full user objects)?

### Table 2: State Machines

For every boolean/enum state variable (isGameOver, battleState, Game.running, phase, mode...):

```
| # | Variable | Set by | Read by | Init value | Reset when? | Can it leak across lifecycles? |
```

For each variable, ask:
- If the game/session ends, does this get reset?
- If I start a new round immediately, will stale state from the previous round affect it?
- Are there race conditions between setters?

### Table 3: Timers

For every setTimeout/setInterval:

```
| # | Type | Delay | Created in | Cleared in | What if lifecycle ends before it fires? |
```

For each timer, ask:
- Is the handle stored for cleanup?
- If the game ends / user disconnects / page navigates, does this still fire?
- If it fires after cleanup, does it reference destroyed objects?

### Table 4: Numeric Values

For every user-influenceable number (cost, score, damage, lootValue, kills, quantity...):

```
| # | Name | Source (client/server/config) | Validated? | Min | Max | What if 0? | What if negative? |
```

For each value, ask:
- Is the server-side cap realistic? (kills cap 200 but max enemies is 50?)
- Can the client send a value the server trusts without verification?
- Float precision issues? (accumulated math â†’ 290402.0000000001)

### Table 5: Data Flows (Critical!)

For every pair of related APIs (buyâ†’use, startâ†’complete, payâ†’deliver, loginâ†’action):

```
| # | Step 1 API | Step 2 API | Token/link between them? | Can skip Step 1? | Can replay Step 1? |
```

This is where the biggest bugs hide. For each flow, ask:
- Can I call Step 2 without ever calling Step 1? (raid-result without buy)
- Can I call Step 1 once but Step 2 many times? (buy once, submit results 10 times)
- Is there a one-time token linking them? If not, this is a critical vulnerability.
- Can I call Step 1 with cost=0 then Step 2 with high reward?

### Table 6: Resource Ledger

For every in-game resource (coins, gems, items, XP, energy...):

```
| # | Resource | All INFLOWS (APIs/events that add) | All OUTFLOWS (APIs/events that subtract) | Daily limits? | Can any inflow be infinite? |
```

For each resource, ask:
- Is there any inflow without a corresponding cost? (free coins from quest with no cooldown)
- Can any outflow go negative? (sell item â†’ coins, but what if coins overflow?)
- Are items in safe-box excluded from ALL outflows? (trade, sell, merge, fuse, gift)
- Is there a loop? (buy item A â†’ sell for more than cost â†’ repeat)

### Table 7: Concurrency Hotspots (TOCTOU)

For every operation that reads-then-writes shared state (balance checkâ†’deduct, stock checkâ†’reserve, coupon checkâ†’redeem):

```
| # | Operation | Read step | Write step | Atomic? | What if 2 requests hit simultaneously? |
```

This catches race conditions that single-request testing misses. For each operation, ask:
- Is the read-then-write atomic? (SQL `UPDATE x=x-1 WHERE x>=1` is atomic; `SELECT` then `UPDATE` is NOT)
- Can two concurrent requests both pass the check and both execute the write? (double-spend)
- Is there a mutex/lock/transaction? If using SQLite, is WAL mode enabled for concurrent reads?
- For multi-step flows: can request A be between steps while request B starts the same flow?

## Phase 2: Verify (main audit)

Go through every row in every table. For each row, determine:
- ğŸ”´ Critical: exploitable security hole, data loss, crash
- ğŸŸ¡ Medium: logic error, inconsistency, performance issue  
- ğŸŸ¢ Minor: code quality, edge case, UX issue
- âœ… OK: verified correct

Output format:
```
Bug N: [ğŸ”´/ğŸŸ¡/ğŸŸ¢] Brief description
- Row: Table X, #Y
- Cause: ...
- Fix: ...
- File: ...
```

**Do NOT stop when you run out of "inspiration".** You stop when every row in every table has been verified âœ… or flagged ğŸ”´/ğŸŸ¡/ğŸŸ¢. This is exhaustive, not heuristic.

## Phase 3: Red Team / Blue Team

After verifying all tables, switch to adversarial mode. Read `references/redblue.md` for the full playbook.

### Structure
The playbook has 4 parts:
1. **Universal Chains (5)** â€” apply to ALL projects: Auth Bypass, Injection, Rate Abuse, Data Leakage, Concurrency/Race Conditions
2. **Type-Specific Chains** â€” pick sections matching the project:
   - ğŸ® Game: Skip-Pay-Collect, Economic Loop, State Manipulation, Anti-Cheat Bypass
   - ğŸ“Š Data Tool: Data Access Control, Data Integrity, Scheduled Task Abuse
   - ğŸ”Œ API Service: Key/Token Abuse, Upstream Dependency, Response Manipulation
   - ğŸ¤– Bot: Message Injection, Bot State Abuse
   - ğŸ”§ WeChat: OAuth & Identity, WebView Compatibility, H5 Hybrid
   - ğŸ“ˆ Platform: Cross-Service Trust, Multi-Tenant Isolation
3. **Blue Team Defense** â€” for each finding, verify 4 layers: Prevention â†’ Detection â†’ Containment â†’ Recovery
4. **Execution Guide** â€” step-by-step for the auditor

### How to Run
1. From Phase 1 dissection, identify project type(s) â€” a project can match multiple types
2. Run ALL 5 Universal Chains
3. Run type-specific chains matching the project
4. For each ğŸ”´ finding: verify all 4 Blue Team layers
5. For each ğŸŸ¡ finding: verify Layer 1 (Prevention) at minimum

## Phase 4: Supplement

After red/blue team, run generic checks as a final safety net. Read `references/modules.md` and pick sections matching the project:

- ğŸ”’ Security (S1-S3): CORS, XSS, SQLi, brute force â€” if project has users
- ğŸ” Crypto (C1): Hardcoded secrets, weak hashing, plaintext storage, insecure random â€” all projects
- ğŸ“Š Data (D1-D3): Timezone, atomic ops, float precision â€” if project has DB
- âš¡ Performance (P1-P2): Memory leaks, hot paths â€” if project is large/realtime
- ğŸ® Game (G1-G4): State guards, rendering, config â€” if project is a game
- ğŸ”§ WeChat (W1-W3): ES6 compat, CDN, debugging â€” if runs in WeChat WebView
- ğŸ”Œ API (A1-A3): Interface standards, rate limiting â€” if project is an API service
- ğŸ¤– Bot (B1): Timeout, dedup, sensitive words â€” if project is a bot
- ğŸš€ Deploy (R1-R2): PM2, nginx, SSL, SDK overwrite â€” all projects
- ğŸ§ª Error Handling (E1-E2): Network errors, server errors, graceful degradation â€” all projects
- ğŸ“± UX Robustness (U1-U2): Error states, edge case UX â€” all projects with UI
- ğŸ“¦ Supply Chain (SC1): npm audit, dependency vulnerabilities, lockfile integrity â€” all Node.js projects
- ğŸ“ Logging (L1): Security event logging, audit trail completeness â€” all projects with users

## Phase 5: Regression + Verify

- Check that fixes didn't introduce new bugs
- After modular split: verify cross-file variable/function reachability
- Live smoke test: homepage 200, key APIs return JSON, login works, core feature functional

## Phase 6: Archive

Update project docs with: date, tables built, bugs found/fixed, key pitfalls for next audit.

## Key Principles

1. **Tables first, checking second.** Building the tables IS the hard work. Once you have them, verification is mechanical.
2. **Exhaustive, not heuristic.** Don't stop when you "feel done." Stop when every row is verified.
3. **Think like an attacker.** For every API: "How would I exploit this?" For every value: "What if I send garbage?"
4. **Data flows are where critical bugs hide.** The link (or lack thereof) between related APIs is the #1 source of exploitable vulnerabilities.
5. **Generic checklists are supplements, not the main event.** They catch known patterns; the tables catch project-specific logic bugs.

## Reference Files

- `references/modules.md` â€” Generic audit modules (Security, Crypto, Data, Performance, Game, WeChat, API, Bot, Deploy, Error Handling, UX, Supply Chain, Logging) for Phase 4 supplementary checks.
- `references/redblue.md` â€” Red team attack chains (universal + 6 project types) and blue team defense verification playbook for Phase 3.
- `references/pitfalls.md` â€” Real-world pitfall lookup table from 200+ bugs, plus WeChat WebView remote debugging techniques.
